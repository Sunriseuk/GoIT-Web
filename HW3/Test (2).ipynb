{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Багатопоточність"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before func_1 sleep_time=2\n",
      "After func_1 sleep_time=2\n",
      "Before func_2 sleep_time=2\n",
      "After func_2 sleep_time=2\n",
      "Before func_1 sleep_time=3\n",
      "Before func_2 sleep_time=5\n",
      "4.01243782043457\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After func_1 sleep_time=3\n",
      "After func_2 sleep_time=5\n"
     ]
    }
   ],
   "source": [
    "from threading import Thread, Lock, RLock\n",
    "from time import sleep, time\n",
    "\n",
    "before = time()\n",
    "\n",
    "def func_1(sleep_time: int):\n",
    "    print(f'Before func_1 {sleep_time=}')\n",
    "    sleep(sleep_time)\n",
    "    print(f'After func_1 {sleep_time=}')\n",
    "\n",
    "def func_2(sleep_time: int):\n",
    "    print(f'Before func_2 {sleep_time=}')\n",
    "    sleep(sleep_time)\n",
    "    print(f'After func_2 {sleep_time=}')\n",
    "\n",
    "func_1(2)\n",
    "func_2(2)\n",
    "\n",
    "after = time()\n",
    "\n",
    "t1 = Thread(target=func_1, args=(3,))\n",
    "t2 = Thread(target=func_2, args=(5,))\n",
    "\n",
    "t1.start()\n",
    "t2.start()\n",
    "\n",
    "print(f'{after-before}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Thread-6 (func) Time 3.0026657581329346\n",
      "Thread-7 (func) Time 5.00277853012085\n"
     ]
    }
   ],
   "source": [
    "from threading import Thread, Lock, RLock\n",
    "from time import sleep, time\n",
    "import logging\n",
    "\n",
    "# logger = logging.getLogger(__name__)\n",
    "logging.basicConfig(level=logging.DEBUG, format='%(threadName)s %(message)s') \n",
    "\n",
    "lock = Lock()\n",
    "\n",
    "def func(t: int, locker):\n",
    "    time1 = time()\n",
    "    sleep(t)\n",
    "    time2 = time()\n",
    "    logging.debug(f'Time {time2 - time1}')\n",
    "\n",
    "t1 = Thread(target=func, args=(3, lock))\n",
    "t2 = Thread(target=func, args=(5, lock))\n",
    "\n",
    "t1.start()\n",
    "t1.join()\n",
    "t2.start()\n",
    "t2.join()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Thread-10 (func) Time 3.00380277633667\n",
      "Thread-11 (func) Time 8.021104097366333\n"
     ]
    }
   ],
   "source": [
    "from threading import Thread, Lock, RLock\n",
    "from time import sleep, time\n",
    "import logging\n",
    "\n",
    "# logger = logging.getLogger(__name__)\n",
    "logging.basicConfig(level=logging.DEBUG, format='%(threadName)s %(message)s') \n",
    "\n",
    "lock = Lock()\n",
    "\n",
    "def func(t: int, locker: Lock):\n",
    "    time1 = time()\n",
    "    locker.acquire()\n",
    "    sleep(t)\n",
    "    time2 = time()\n",
    "    locker.release()\n",
    "    logging.debug(f'Time {time2 - time1}')\n",
    "\n",
    "t1 = Thread(target=func, args=(3, lock))\n",
    "t2 = Thread(target=func, args=(5, lock))\n",
    "\n",
    "t1.start()\n",
    "t2.start()\n",
    "t1.join()\n",
    "t2.join()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Thread-12 (func) Time 3.007138967514038\n",
      "Thread-13 (func) Time 8.026324033737183\n"
     ]
    }
   ],
   "source": [
    "from threading import Thread, Lock, RLock\n",
    "from time import sleep, time\n",
    "import logging\n",
    "\n",
    "# logger = logging.getLogger(__name__)\n",
    "logging.basicConfig(level=logging.DEBUG, format='%(threadName)s %(message)s') \n",
    "\n",
    "lock = Lock()\n",
    "\n",
    "def func(t: int, locker: Lock):\n",
    "    time1 = time()\n",
    "    with locker:\n",
    "        sleep(t)\n",
    "    time2 = time()\n",
    "    logging.debug(f'Time {time2 - time1}')\n",
    "\n",
    "t1 = Thread(target=func, args=(3, lock))\n",
    "t2 = Thread(target=func, args=(5, lock))\n",
    "\n",
    "t1.start()\n",
    "t2.start()\n",
    "t1.join()\n",
    "t2.join()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import threading\n",
    "\n",
    "def get_data(data): #Имя потока и данные, которые он будет передавать\n",
    "    print(f'[{threading.currentThread().name}] - {data}')\n",
    "    time.sleep(5)\n",
    "\n",
    "thr = threading.Thread(target=get_data, args=(str(time.time()),), name='Thr-1')\n",
    "thr.start()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import threading\n",
    "\n",
    "def get_data(data): #Имя потока и данные, которые он будет передавать\n",
    "    for i in range(20):\n",
    "        print(f'[{threading.currentThread().name}] - {data}')\n",
    "        time.sleep(1)\n",
    "\n",
    "thr = threading.Thread(target=get_data, args=(str(time.time()),), name='Thr-1')\n",
    "thr.start()\n",
    "\n",
    "print('name:', threading.main_thread().name)\n",
    "threading.main_thread().setName('result')\n",
    "print(\"result:\", threading.main_thread().name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import threading\n",
    "\n",
    "def get_data(data): #Имя потока и данные, которые он будет передавать\n",
    "    for i in range(20):\n",
    "        print(f'[{threading.currentThread().name}] - {data}')\n",
    "        time.sleep(1)\n",
    "\n",
    "thr = threading.Thread(target=get_data, args=(str(time.time()),), name='Thr-1')\n",
    "thr.start()\n",
    "\n",
    "for i in range(20):\n",
    "    print(f'current: {i}')\n",
    "    time.sleep(1)\n",
    "\n",
    "    if i % 10 == 0:\n",
    "        print('active thread:', threading.active_count())\n",
    "        print('enumerate:', threading.enumerate())\n",
    "        print('thr-1 is alive:', thr.is_alive())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import threading\n",
    "\n",
    "def get_data(data): #Имя потока и данные, которые он будет передавать\n",
    "    for i in range(20):\n",
    "        print(f'[{threading.currentThread().name}] - {data}')\n",
    "        time.sleep(1)\n",
    "\n",
    "thr = threading.Thread(target=get_data, args=(str(time.time()),), name='Thr-1')\n",
    "thr.start()\n",
    "\n",
    "for i in range(20):\n",
    "    print(f'current: {i}')\n",
    "    time.sleep(1)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Задача, которая выполняется только тогда, когда выполнены все потоки"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import threading\n",
    "\n",
    "def get_data(data, value): \n",
    "    for _ in range(value):\n",
    "        print(f'[{threading.currentThread().name}] - {data}')\n",
    "        time.sleep(1)\n",
    "\n",
    "thr_list = []\n",
    "\n",
    "for i in range(3):\n",
    "    thr = threading.Thread(target=get_data, args=(str(time.time()), i,), name='Thr-1')\n",
    "    thr_list.append(thr)\n",
    "    thr.start()\n",
    "\n",
    "for i in thr_list:\n",
    "    i.join()\n",
    "\n",
    "print('finish')    \n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Поток как класс\n",
    "\n",
    "Это означает, что основной поток приложения сначала вывел 'Usefull message' и после него через 2 секунды пять потоков MyThread вывели своё 'Wake up!', и только после этого скрипт завершился."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Usefull message\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Thread-7 Wake up!\n",
      "Thread-7 args: ('Count thread - 4',)\n",
      "Thread-6 Wake up!\n",
      "Thread-6 args: ('Count thread - 3',)\n",
      "Thread-5 Wake up!\n",
      "Thread-5 args: ('Count thread - 2',)\n",
      "Thread-4 Wake up!\n",
      "Thread-3 Wake up!\n",
      "Thread-4 args: ('Count thread - 1',)\n",
      "Thread-3 args: ('Count thread - 0',)\n"
     ]
    }
   ],
   "source": [
    "from threading import Thread\n",
    "import logging\n",
    "from time import sleep\n",
    "\n",
    "\n",
    "class MyThread(Thread):\n",
    "    def __init__(self, group=None, target=None, name=None, args=(), kwargs=None, *, daemon=None):\n",
    "        super().__init__(group=group, target=target, name=name, daemon=daemon)\n",
    "        self.args = args\n",
    "        self.kwargs = kwargs\n",
    "\n",
    "    def run(self) -> None:\n",
    "        sleep(2)\n",
    "        logging.debug('Wake up!')\n",
    "        logging.debug(f\"args: {self.args}\")\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    logging.basicConfig(level=logging.DEBUG, format='%(threadName)s %(message)s')\n",
    "    for i in range(5):\n",
    "        thread = MyThread(args=(f\"Count thread - {i}\",))\n",
    "        thread.start()\n",
    "    print('Usefull message')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Поток как функтор\n",
    "\n",
    "Есть другой способ выполнить код в отдельном потоке. Для этого надо, чтобы код выполнения, был функтором (функцией или классом, у которого есть метод __call__). Тогда объект можно передать как именованный аргумент target в Thread:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Some stuff\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Thread-8 Wake up!\n"
     ]
    }
   ],
   "source": [
    "from threading import Thread\n",
    "from time import sleep\n",
    "import logging\n",
    "\n",
    "\n",
    "class UsefulClass():\n",
    "    def __init__(self, second_num):\n",
    "        self.delay = second_num\n",
    "\n",
    "    def __call__(self):\n",
    "        sleep(self.delay)\n",
    "        logging.debug('Wake up!')\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    logging.basicConfig(level=logging.DEBUG, format='%(threadName)s %(message)s')\n",
    "    t2 = UsefulClass(2)\n",
    "    thread = Thread(target=t2)\n",
    "    thread.start()\n",
    "    print('Some stuff')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Поток в функции\n",
    "\n",
    "В процессе создания экземпляра класса Thread можно передать аргументу target функцию и передать ей аргументы.\n",
    "\n",
    "Обратите внимание, что аргументы, которые надо передать в функцию, передаются как кортеж args в Thread. Именованные аргументы для функции можно так же передать как словарь kwargs в Thread."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Thread-9 (example_work) Wake up!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Thread-10 (example_work) Wake up!\n",
      "Thread-11 (example_work) Wake up!\n",
      "Thread-12 (example_work) Wake up!\n",
      "Thread-13 (example_work) Wake up!\n"
     ]
    }
   ],
   "source": [
    "from threading import Thread\n",
    "from time import sleep\n",
    "import logging\n",
    "\n",
    "\n",
    "def example_work(delay):\n",
    "    sleep(delay)\n",
    "    logging.debug('Wake up!')\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    logging.basicConfig(level=logging.DEBUG, format='%(threadName)s %(message)s')\n",
    "    for i in range(5):\n",
    "        thread = Thread(target=example_work, args=(i,))\n",
    "        thread.start()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ожидание выполнения потока\n",
    "\n",
    "Когда надо в основном приложении дождаться выполнения потока можно воспользоваться блокирующим методом join.\n",
    "\n",
    "Основной поток дождался [el.join() for el in threads], пока завершатся все потоки thread из списка threads, и только потом вывел End program.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MainThread Start program\n",
      "Thread-14 (example_work) Wake up!\n",
      "Thread-15 (example_work) Wake up!\n",
      "Thread-16 (example_work) Wake up!\n",
      "Thread-17 (example_work) Wake up!\n",
      "Thread-18 (example_work) Wake up!\n",
      "MainThread End program\n"
     ]
    }
   ],
   "source": [
    "from threading import Thread\n",
    "import logging\n",
    "from time import sleep\n",
    "\n",
    "\n",
    "def example_work(params):\n",
    "    sleep(params)\n",
    "    logging.debug('Wake up!')\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    logging.basicConfig(level=logging.DEBUG, format='%(threadName)s %(message)s')\n",
    "    logging.debug('Start program')\n",
    "    threads = []\n",
    "    for i in range(5):\n",
    "        thread = Thread(target=example_work, args=(i,))\n",
    "        thread.start()\n",
    "        threads.append(thread)\n",
    "\n",
    "    [el.join() for el in threads]\n",
    "\n",
    "    logging.debug('End program')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Вы также можете явно проверить — выполняется ли поток, вызвав метод is_alive. \n",
    "Это может быть полезно, если вы хотите проверять состояние потока самостоятельно и не блокировать приложение в ожидании завершения."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True False\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Thread-20 Wake up!\n",
      "Thread-19 Wake up!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False False\n",
      "After all...\n"
     ]
    }
   ],
   "source": [
    "from threading import Thread\n",
    "from time import sleep\n",
    "import logging\n",
    "\n",
    "\n",
    "class UsefulClass:\n",
    "    def __init__(self, second_num):\n",
    "        self.delay = second_num\n",
    "\n",
    "    def __call__(self):\n",
    "        sleep(self.delay)\n",
    "        logging.debug('Wake up!')\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    logging.basicConfig(level=logging.DEBUG, format='%(threadName)s %(message)s')\n",
    "    t2 = UsefulClass(2)\n",
    "    thread = Thread(target=t2)\n",
    "    thread_locking = Thread(target=t2)\n",
    "\n",
    "    thread.start()\n",
    "    print(thread.is_alive(), thread_locking.is_alive())\n",
    "    thread_locking.start()\n",
    "    thread.join()\n",
    "    thread_locking.join()\n",
    "    print(thread.is_alive(), thread_locking.is_alive())\n",
    "    print('After all...')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Потоки Демоны"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Thread-4 (get_data)] - 1670698729.63946finish\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Thread-4 (get_data)] - 1670698729.63946\n",
      "[Thread-4 (get_data)] - 1670698729.63946\n",
      "[Thread-4 (get_data)] - 1670698729.63946\n",
      "[Thread-4 (get_data)] - 1670698729.63946\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "import threading\n",
    "\n",
    "def get_data(data):\n",
    "    for _ in range(5):\n",
    "        print(f'[{threading.current_thread().name}] - {data}')\n",
    "        time.sleep(1)\n",
    "\n",
    "thr = threading.Thread(target=get_data, args=(str(time.time()),), daemon=True)\n",
    "# thr.setDaemon(True)\n",
    "thr.start()\n",
    "time.sleep(1)\n",
    "\n",
    "print('finish')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Потоки Timer\n",
    "\n",
    "Экземпляры класса Timer начинают работать с некоторой задержкой, которую определяет программист. Кроме того эти потоки можно отменить в любой момент периода задержки. Например, вы передумали стартовать некоторый поток.\n",
    "\n",
    "Здесь мы запланировали выполнение двух потоков, через 0.5 и 0.7 секунд. Но потом через 0.6 секунды отменили выполнение второго потока second.cancel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MainThread Start timers\n",
      "First thread Start!\n",
      "MainThread End program\n"
     ]
    }
   ],
   "source": [
    "from threading import Timer\n",
    "import logging\n",
    "from time import sleep\n",
    "\n",
    "\n",
    "def example_work():\n",
    "    logging.debug('Start!')\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    logging.basicConfig(level=logging.DEBUG, format='%(threadName)s %(message)s')\n",
    "\n",
    "    first = Timer(0.5, example_work)\n",
    "    first.name = 'First thread'\n",
    "    second = Timer(0.7, example_work)\n",
    "    second.name = 'Second thread'\n",
    "    logging.debug('Start timers')\n",
    "    first.start()\n",
    "    second.start()\n",
    "    sleep(0.6)\n",
    "    second.cancel()\n",
    "\n",
    "    logging.debug('End program')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import threading\n",
    "import time\n",
    "\n",
    "def test():\n",
    "    for i in range(20):\n",
    "        print('test')\n",
    "        time.sleep(1)\n",
    "\n",
    "threading.Timer(10, test).start() #time, function\n",
    "# thr = threading.Timer(10, test)\n",
    "# thr.start()\n",
    "\n",
    "for i in range (20):\n",
    "    print('111')\n",
    "    time.sleep(2)\n",
    "\n",
    "         \n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Отмена запуска потока"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import threading\n",
    "import time\n",
    "\n",
    "def test():\n",
    "    for i in range(20):\n",
    "        print('test')\n",
    "        time.sleep(1)\n",
    "\n",
    "thr = threading.Timer(5, test)\n",
    "thr.start()\n",
    "\n",
    "for _ in range (3):\n",
    "    print('111')\n",
    "    time.sleep(1)\n",
    "\n",
    "thr.cancel()\n",
    "print('finish')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import threading\n",
    "import time\n",
    "\n",
    "def test():\n",
    "    for i in range(20):\n",
    "        print('test')\n",
    "        time.sleep(1)\n",
    "\n",
    "thr = threading.Timer(5, test)\n",
    "thr.setDaemon(True)\n",
    "thr.start()\n",
    "\n",
    "for _ in range (6):\n",
    "    print('111')\n",
    "    time.sleep(1)\n",
    "\n",
    "thr.cancel()\n",
    "print('finish')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Хранилище Local"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import threading\n",
    "import time\n",
    "\n",
    "data = threading.local()\n",
    "\n",
    "def get():\n",
    "    print(data.value)\n",
    "\n",
    "def t1():\n",
    "    data.value = 111\n",
    "    get()\n",
    "\n",
    "def t2():\n",
    "    data.value = 222\n",
    "    get()\n",
    "\n",
    "threading.Thread(target=t1).start()\n",
    "threading.Thread(target=t2).start()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import threading\n",
    "import time\n",
    "\n",
    "data = threading.local()\n",
    "\n",
    "def t1():\n",
    "    data.value = {'value': 1}\n",
    "    print('T1:', data.value)\n",
    "\n",
    "def t2():\n",
    "    data.test = ['test1', 'test2']\n",
    "    print('T2:', data.test)\n",
    "\n",
    "threading.Thread(target=t1).start()\n",
    "threading.Thread(target=t2).start()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import threading\n",
    "import time\n",
    "\n",
    "data = threading.local()\n",
    "\n",
    "def get_name():\n",
    "    print(data.name)\n",
    "\n",
    "def t1():\n",
    "    data.name = threading.current_thread().name\n",
    "    get_name()\n",
    "\n",
    "def t2():\n",
    "    data.name = threading.current_thread().name\n",
    "    get_name()\n",
    "\n",
    "threading.Thread(target=t1, name='t1').start()\n",
    "threading.Thread(target=t2, name='t2').start()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Блокировки\n",
    "\n",
    "Для это есть механизм блокировок. В Python есть два примитива блокировок: Lock и RLock. Lock немного быстрее и более низкоуровневый, но он не рекурсивный и может быть ситуация попадания в DeadLock, когда выполнение кода заблокируется, несколько потоков будут ожидать, пока кто-то отдаст Lock, а его никто никогда уже не отдаст. Это и есть ситуация, когда приложение \"зависло\".\n",
    "\n",
    "RLock немного медленнее, но зато исключает взаимную блокировку. Рекомендуется всегда использовать именно его, если нет веских причин использовать Lock.\n",
    "\n",
    "Такой вывод означает, что один из потоков \"взял\" lock и пока он его не \"отпустил\", другой ожидал пока lock освободится. Блокировка ресурса достигается выполнением команды locker.acquire(). Это делается, чтобы общим ресурсом мог пользоваться только один поток в один момент времени, и только когда поток закончит работу с общим ресурсом, он отпускает lock, в нашем случае команда locker.release(), и кто-то другой сможет поработать с ресурсом. Так гарантируется, что общий ресурс не попадет в неопределенное состояние, когда кто-то начал с ним работу и не закончил, и кто-то другой начал, и так далее."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MainThread Started\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Thread-23 (func) Done 2.00685977935791\n",
      "Thread-24 (func) Done 4.029395341873169\n"
     ]
    }
   ],
   "source": [
    "from threading import Thread, RLock\n",
    "import logging\n",
    "from time import time, sleep\n",
    "\n",
    "lock = RLock()\n",
    "\n",
    "\n",
    "def func(locker, delay):\n",
    "    timer = time()\n",
    "    locker.acquire()\n",
    "    sleep(delay)\n",
    "    locker.release()\n",
    "    logging.debug(f'Done {time() - timer}')\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    logging.basicConfig(level=logging.DEBUG, format='%(threadName)s %(message)s')\n",
    "    t1 = Thread(target=func, args=(lock, 2))\n",
    "    t2 = Thread(target=func, args=(lock, 2))\n",
    "    t1.start()\n",
    "    t2.start()\n",
    "    logging.debug('Started')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Но чаще для блокировки используют контекст выполнения:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MainThread Started\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Thread-25 (func) Done 2.0133512020111084\n",
      "Thread-26 (func) Done 4.024360179901123\n"
     ]
    }
   ],
   "source": [
    "from threading import Thread, RLock\n",
    "import logging\n",
    "from time import time, sleep\n",
    "\n",
    "lock = RLock()\n",
    "\n",
    "\n",
    "def func(locker, delay):\n",
    "    timer = time()\n",
    "    with locker:\n",
    "        sleep(delay)\n",
    "    logging.debug(f'Done {time() - timer}')\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    logging.basicConfig(level=logging.DEBUG, format='%(threadName)s %(message)s')\n",
    "    t1 = Thread(target=func, args=(lock, 2))\n",
    "    t2 = Thread(target=func, args=(lock, 2))\n",
    "    t1.start()\n",
    "    t2.start()\n",
    "    logging.debug('Started')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import threading\n",
    "import time\n",
    "\n",
    "value = 0\n",
    "locker = threading.Lock()\n",
    "\n",
    "def inc_value():\n",
    "    global value\n",
    "    for i in range(20):\n",
    "        locker.acquire()\n",
    "        value += 1\n",
    "        print(value)\n",
    "        locker.release()\n",
    "\n",
    "for _ in range(5):\n",
    "    threading.Thread(target=inc_value).start()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import threading\n",
    "import time\n",
    "\n",
    "value = 0\n",
    "locker = threading.Lock()\n",
    "\n",
    "def inc_value():\n",
    "    global value\n",
    "    for i in range(20):\n",
    "        with locker:\n",
    "            value += 1\n",
    "            print(value)\n",
    "        \n",
    "for _ in range(5):\n",
    "    threading.Thread(target=inc_value).start()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import threading\n",
    "\n",
    "locker = threading.Lock()\n",
    "\n",
    "\n",
    "def inc_value():\n",
    "    print('Блокируем поток...')\n",
    "    locker.acquire()\n",
    "    print(\"Поток разблокирован...\")\n",
    "\n",
    "t1 = threading.Thread(target=inc_value)\n",
    "t1 = threading.Thread(target=inc_value)\n",
    "t1.start()\n",
    "t2.start()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import threading\n",
    "\n",
    "locker = threading.RLock()\n",
    "\n",
    "\n",
    "def inc_value():\n",
    "    print('Блокируем поток...')\n",
    "    locker.acquire()\n",
    "    print(\"Поток разблокирован...\")\n",
    "\n",
    "t1 = threading.Thread(target=inc_value)\n",
    "t1 = threading.Thread(target=inc_value)\n",
    "t1.start()\n",
    "t2.start()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Семафоры\n",
    "\n",
    "В качестве примера рассмотрим выполнение 10 потоков и ограничим выполнение, с помощью семафора, до двух одновременно: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Th-0 Got semaphore\n",
      "Th-1 Got semaphore\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Th-0 finished\n",
      "Th-2 Got semaphore\n",
      "Th-1 finished\n",
      "Th-3 Got semaphore\n",
      "Th-2 finished\n",
      "Th-4 Got semaphore\n",
      "Th-3 finished\n",
      "Th-5 Got semaphore\n",
      "Th-4 finished\n",
      "Th-6 Got semaphore\n",
      "Th-5 finished\n",
      "Th-7 Got semaphore\n",
      "Th-6 finished\n",
      "Th-7 finished\n",
      "Th-8 Got semaphore\n",
      "Th-9 Got semaphore\n",
      "Th-9 finished\n",
      "Th-8 finished\n"
     ]
    }
   ],
   "source": [
    "from threading import Semaphore, Thread\n",
    "import logging\n",
    "from time import sleep\n",
    "\n",
    "\n",
    "def worker(condition):\n",
    "    with condition:\n",
    "        logging.debug(f'Got semaphore')\n",
    "        sleep(1)\n",
    "        logging.debug(f'finished')\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    logging.basicConfig(level=logging.DEBUG, format='%(threadName)s %(message)s')\n",
    "    pool = Semaphore(2)\n",
    "    for num in range(10):\n",
    "        thread = Thread(name=f'Th-{num}', target=worker, args=(pool, ))\n",
    "        thread.start()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from threading import Thread, BoundedSemaphore, currentThread\n",
    "import time\n",
    "\n",
    "max_connections = 5\n",
    "\n",
    "pool = BoundedSemaphore(value=max_connections)\n",
    "\n",
    "def test():\n",
    "    for i in range(10):\n",
    "        with pool: #короткая запись запуска потков\n",
    "            print(currentThread().name)\n",
    "            time.sleep(2) \n",
    "\n",
    "Thread(target=test).start()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from threading import Thread, BoundedSemaphore, currentThread\n",
    "import time\n",
    "\n",
    "max_connections = 5\n",
    "\n",
    "pool = BoundedSemaphore(value=max_connections)\n",
    "\n",
    "def test():\n",
    "    for i in range(10):\n",
    "        with pool: #короткая запись запуска потков\n",
    "            print(currentThread().name)\n",
    "            time.sleep(6) \n",
    "\n",
    "for i in range(10):\n",
    "    Thread(target=test, name=f'thr-{i}').start()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from threading import Thread, BoundedSemaphore, currentThread\n",
    "import time\n",
    "import random\n",
    "\n",
    "max_connections = 5\n",
    "\n",
    "pool = BoundedSemaphore(value=max_connections)\n",
    "\n",
    "def test():\n",
    "    with pool:\n",
    "        slp = random.randint(1, 5) \n",
    "        print(f'{currentThread().name} - sleep ({slp})')\n",
    "        time.sleep(slp) \n",
    "\n",
    "for i in range(10):\n",
    "    Thread(target=test, name=f'thr-{i}').start()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Синхронизация потоков"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Condition\n",
    "\n",
    "Есть примитивы синхронизации, которые позволяют потокам ожидать сигнала от других потоков — это Condition. Создадим две разные функции: одна master будет уведомлять, что worker может продолжить работу. При этом они будут выполняться в разных потоках.\n",
    "\n",
    "Вначале master в потоке выполняет некую работу. После он выполняет метод condition.notify_all() чем разрешает запустить остальные потоки ожидающие выполнения. Они ожидают выполнения в точке вызова метода condition.wait().\n",
    "\n",
    "Если же master должен разрешить работу только одному из worker, можно вызвать метод condition.notify(), тогда только один из ожидающих разрешения worker продолжит работу. Второй будет ожидать, пока не будет выполнено следующее condition.notify."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "worker_one Worker ready to work\n",
      "worker_two Worker ready to work\n",
      "master Master doing some work\n",
      "MainThread End program\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "master Informing that workers can do the work\n",
      "worker_one The worker can do the work\n",
      "worker_two The worker can do the work\n"
     ]
    }
   ],
   "source": [
    "from threading import Thread, Condition\n",
    "import logging\n",
    "from time import sleep\n",
    "\n",
    "\n",
    "def worker(condition: Condition):\n",
    "    logging.debug('Worker ready to work')\n",
    "    with condition:\n",
    "        condition.wait()\n",
    "        logging.debug('The worker can do the work')\n",
    "\n",
    "\n",
    "def master(condition: Condition):\n",
    "    logging.debug('Master doing some work')\n",
    "    sleep(2)\n",
    "    with condition:\n",
    "        logging.debug('Informing that workers can do the work')\n",
    "        condition.notify_all()\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    logging.basicConfig(level=logging.DEBUG, format='%(threadName)s %(message)s')\n",
    "    condition = Condition()\n",
    "    master = Thread(name='master', target=master, args=(condition,))\n",
    "\n",
    "    worker_one = Thread(name='worker_one', target=worker, args=(condition, ))\n",
    "    worker_two = Thread(name='worker_two', target=worker, args=(condition,))\n",
    "    worker_one.start()\n",
    "    worker_two.start()\n",
    "    master.start()\n",
    "\n",
    "    logging.debug('End program')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Event\n",
    "\n",
    "Другой примитив синхронизации — это потокобезопасный флаг класса Event. Класс Event имеет внутренний флаг, который могут устанавливать или сбрасывать другие потоки. Для этого используют метод set, чтобы установить флаг и метод clear для сброса. Метода wait класса Event приостанавливает работу потока до тех пор, пока другой поток не установит флаг методом set. Есть возможность проверить установлен ли флаг методом is_set.\n",
    "\n",
    "Таким образом, master может установить флаг класса Event, и все worker потоки продолжат работу только после получения разрешения."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "worker_one Worker ready to work\n",
      "worker_two Worker ready to work\n",
      "master Master doing some work\n",
      "MainThread End program\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "master Informing that workers can do the work\n",
      "worker_one The worker can do the work\n",
      "worker_two The worker can do the work\n"
     ]
    }
   ],
   "source": [
    "from threading import Thread, Event\n",
    "import logging\n",
    "from time import sleep\n",
    "\n",
    "\n",
    "def worker(event: Event):\n",
    "    logging.debug('Worker ready to work')\n",
    "    event.wait()\n",
    "    logging.debug('The worker can do the work')\n",
    "\n",
    "\n",
    "def master(event: Event):\n",
    "    logging.debug('Master doing some work')\n",
    "    sleep(2)\n",
    "    logging.debug('Informing that workers can do the work')\n",
    "    event.set()\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    logging.basicConfig(level=logging.DEBUG, format='%(threadName)s %(message)s')\n",
    "    event = Event()\n",
    "    master = Thread(name='master', target=master, args=(event, ))\n",
    "\n",
    "    worker_one = Thread(name='worker_one', target=worker, args=(event, ))\n",
    "    worker_two = Thread(name='worker_two', target=worker, args=(event,))\n",
    "    worker_one.start()\n",
    "    worker_two.start()\n",
    "    master.start()\n",
    "\n",
    "    logging.debug('End program')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "мы можем управлять выполнением, перезапуском и остановкой работы потоков через класс Event. Например, в следующем примере мы прерываем выполнение потока, который работает в бесконечном цикле и по другому просто никогда не завершится."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Thread-27 (example_work) Run event work\n",
      "Thread-27 (example_work) Run event work\n",
      "Thread-27 (example_work) Run event work\n",
      "Thread-27 (example_work) Run event work\n",
      "MainThread End program\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Thread-27 (example_work) Run event work\n"
     ]
    }
   ],
   "source": [
    "from threading import Thread, Event\n",
    "import logging\n",
    "from time import sleep\n",
    "\n",
    "\n",
    "def example_work(event_for_exit: Event):\n",
    "    while True:\n",
    "        sleep(1)\n",
    "        logging.debug('Run event work')\n",
    "\n",
    "        if event_for_exit.is_set():\n",
    "            break\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    logging.basicConfig(level=logging.DEBUG, format='%(threadName)s %(message)s')\n",
    "    event = Event()\n",
    "    thread = Thread(target=example_work, args=(event,))\n",
    "    thread.start()\n",
    "\n",
    "    sleep(5)\n",
    "    event.set()\n",
    "\n",
    "    logging.debug('End program')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Barrier\n",
    "\n",
    "Последний примитив синхронизации, который мы рассмотрим в Python — это барьер Barrier. Он позволяет задать условие, чтобы несколько потоков продолжили работу только после того, как заданное число потоков доберется в выполнении кода до этого \"барьера\".\n",
    "\n",
    "Используется, когда вам нужно, чтобы работа приложения продолжилась только после того, как все потоки сделают какую-то часть своей работы и дойдут до некоторой точки, с которой можно опять продолжать.\n",
    "\n",
    "Поток может добраться до барьера и ждать его с помощью функции wait(). Это блокирующий вызов, который вернется, когда все остальные потоки (предварительно настроенное количество barrier = Barrier(5)) достигнут барьера.\n",
    "\n",
    "Функция ожидания wait() возвращает целое число, указывающее на количество оставшихся до барьера участников. Если поток был последним прибывшим, то возвращенное значение будет нулевым."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Th-0 Start thread: Fri Dec  9 22:24:38 2022\n",
      "Th-1 Start thread: Fri Dec  9 22:24:38 2022\n",
      "Th-2 Start thread: Fri Dec  9 22:24:38 2022\n",
      "Th-3 Start thread: Fri Dec  9 22:24:38 2022\n",
      "Th-4 Start thread: Fri Dec  9 22:24:38 2022\n",
      "Th-5 Start thread: Fri Dec  9 22:24:38 2022\n",
      "Th-6 Start thread: Fri Dec  9 22:24:38 2022\n",
      "Th-7 Start thread: Fri Dec  9 22:24:38 2022\n",
      "Th-8 Start thread: Fri Dec  9 22:24:38 2022\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Th-9 Start thread: Fri Dec  9 22:24:38 2022\n",
      "Th-6 count: 4\n",
      "Th-1 count: 1\n",
      "Th-0 count: 0\n",
      "Th-6 Barrier overcome: Fri Dec  9 22:24:39 2022\n",
      "Th-3 count: 3\n",
      "Th-2 count: 2\n",
      "Th-2 Barrier overcome: Fri Dec  9 22:24:39 2022\n",
      "Th-0 Barrier overcome: Fri Dec  9 22:24:39 2022\n",
      "Th-3 Barrier overcome: Fri Dec  9 22:24:39 2022\n",
      "Th-1 Barrier overcome: Fri Dec  9 22:24:39 2022\n",
      "Th-7 count: 4\n",
      "Th-5 count: 0\n",
      "Th-8 count: 2\n",
      "Th-8 Barrier overcome: Fri Dec  9 22:24:41 2022\n",
      "Th-4 count: 3\n",
      "Th-7 Barrier overcome: Fri Dec  9 22:24:41 2022\n",
      "Th-5 Barrier overcome: Fri Dec  9 22:24:41 2022\n",
      "Th-9 count: 1\n",
      "Th-4 Barrier overcome: Fri Dec  9 22:24:41 2022\n",
      "Th-9 Barrier overcome: Fri Dec  9 22:24:41 2022\n"
     ]
    }
   ],
   "source": [
    "from random import randint\n",
    "from threading import Thread, Barrier\n",
    "import logging\n",
    "from time import sleep, ctime\n",
    "\n",
    "\n",
    "def worker(barrier: Barrier):\n",
    "    logging.debug(f'Start thread: {ctime()}')\n",
    "    sleep(randint(1, 3))  # Simulate some work\n",
    "    r = barrier.wait()\n",
    "    logging.debug(f'count: {r}')\n",
    "    logging.debug(f'Barrier overcome: {ctime()}')\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    logging.basicConfig(level=logging.DEBUG, format='%(threadName)s %(message)s')\n",
    "    barrier = Barrier(5)\n",
    "\n",
    "    for num in range(10):\n",
    "        thread = Thread(name=f'Th-{num}', target=worker, args=(barrier, ))\n",
    "        thread.start()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import random\n",
    "import threading\n",
    "from threading import currentThread\n",
    "\n",
    "def test(barrier):\n",
    "    slp = random.randint(3, 7)\n",
    "    time.sleep(slp)\n",
    "    print(f'Поток [{currentThread().name}] запущен в ({time.ctime()})')\n",
    "    \n",
    "\n",
    "    barrier.wait()\n",
    "    print(f'Поток [{currentThread().name}] преодолел барьер в ({time.ctime()})')\n",
    "\n",
    "bar = threading.Barrier(5)\n",
    "for i in range(5):\n",
    "    threading.Thread(target=test, args=(bar,), name=f'thr - {i}').start()\n",
    "    \n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Пул потоков\n",
    "\n",
    "В Python есть ещё один механизм написания асинхронного кода. Вы можете воспользоваться пакетом concurrent.futures. Он позволяет подняться на более высокий уровень абстракции, когда вам просто нужно параллельно выполнить ряд однотипных задач и нет необходимости вдаваться в низкоуровневые детали реализации.\n",
    "\n",
    "Основная идея заключается в использовании реализации абстрактного класса Executor. В concurrent.futures есть две реализации этого абстрактного базового класса: ProcessPoolExecutor — для выполнения кода отдельных процессов (с ним мы познакомимся позже) и ThreadPoolExecutor — для выполнения в отдельных потоках.\n",
    "\n",
    "Каждый такой Executor скрывает набор потоков или процессов, которым вы можете дать работу и получить результат её выполнения. Вам не надо вручную управлять созданием потоков и их корректным завершением.\n",
    "\n",
    "Обратите внимание, что код параллельно выполняется не более чем двумя потоками ThreadPoolExecutor-0_0 и ThreadPoolExecutor-0_1. Результат возвращается только после того, как все входные данные обработаны."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ThreadPoolExecutor-0_0 greeting for: Bill\n",
      "ThreadPoolExecutor-0_1 greeting for: Jill\n",
      "ThreadPoolExecutor-0_1 greeting for: Till\n",
      "ThreadPoolExecutor-0_0 greeting for: Sam\n",
      "ThreadPoolExecutor-0_0 greeting for: Tom\n",
      "ThreadPoolExecutor-0_1 greeting for: John\n",
      "MainThread ['Hello Bill', 'Hello Jill', 'Hello Till', 'Hello Sam', 'Hello Tom', 'Hello John']\n"
     ]
    }
   ],
   "source": [
    "import concurrent.futures\n",
    "import logging\n",
    "from random import randint\n",
    "from time import sleep\n",
    "\n",
    "\n",
    "def greeting(name):\n",
    "    logging.debug(f'greeting for: {name}')\n",
    "    sleep(randint(0, 3))\n",
    "    return f\"Hello {name}\"\n",
    "\n",
    "\n",
    "arguments = (\n",
    "    \"Bill\",\n",
    "    \"Jill\",\n",
    "    \"Till\",\n",
    "    \"Sam\",\n",
    "    \"Tom\",\n",
    "    \"John\",\n",
    ")\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    logging.basicConfig(level=logging.DEBUG, format='%(threadName)s %(message)s')\n",
    "    with concurrent.futures.ThreadPoolExecutor(max_workers=2) as executor:\n",
    "        results = list(executor.map(greeting, arguments))\n",
    "\n",
    "    logging.debug(results)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-----------------------------\n",
    "Пакет multiprocessing\n",
    "-----------------------------\n",
    "\n",
    "Пакет multiprocessing — это пакет для выполнения кода в отдельных процессах с интерфейсом подобным интерфейсу пакета threading."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Для использования процессов необходимо импортировать класс Process модуля multiprocessing. С ним можно работать несколькими способами:\n",
    "\n",
    "    В процессе создания экземпляра класса Process именованному аргументу target передать функцию, которая будет выполняться в отдельном процессе\n",
    "    Реализовать производный класс от класса Process и переопределить метод run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MainThread End program\n",
      "End program\n",
      "End program\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 1 1 1 1 "
     ]
    }
   ],
   "source": [
    "from multiprocessing import Process\n",
    "import logging\n",
    "from time import sleep\n",
    "\n",
    "logger = logging.getLogger()\n",
    "stream_handler = logging.StreamHandler()\n",
    "logger.addHandler(stream_handler)\n",
    "logger.setLevel(logging.DEBUG)\n",
    "\n",
    "\n",
    "class MyProcess(Process):\n",
    "    def __init__(self, group=None, target=None, name=None, args=(), kwargs=None, *, daemon=None):\n",
    "        super().__init__(group=group, target=target, name=name, daemon=daemon)\n",
    "        self.args = args\n",
    "\n",
    "    def run(self) -> None:\n",
    "        logger.debug(self.args)\n",
    "\n",
    "\n",
    "def example_work(params):\n",
    "    sleep(0.5)\n",
    "    logger.debug(params)\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    processes = []\n",
    "    for i in range(3):\n",
    "        pr = Process(target=example_work, args=(f\"Count process function - {i}\", ))\n",
    "        pr.start()\n",
    "        processes.append(pr)\n",
    "\n",
    "    for i in range(2):\n",
    "        pr = MyProcess(args=(f\"Count process class - {i}\",))\n",
    "        pr.start()\n",
    "        processes.append(pr)\n",
    "\n",
    "    [el.join() for el in processes]\n",
    "    [print(el.exitcode, end=' ') for el in processes]\n",
    "    logger.debug('End program')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Contexts and start methods\n",
    "\n",
    " зависимости от платформы multiprocessing поддерживает 3 способа создания нового процесса:\n",
    "\n",
    "    spawn — запускает новый процесс Python, наследуются только ресурсы, необходимые для запуска run(). Присутствует в Unix и Windows. Является способом по умолчанию для Windows и macOS.\n",
    "\n",
    "    fork — дочерний процесс, является точной копией родительского (включая все потоки), доступен только на Unix. По умолчанию используется на Unix. Сделать безопасный fork достаточно проблематично и это может являться причиной неочевидных проблем.\n",
    "\n",
    "    forkserver — создаётся процесс-фабрика (сервер для порождения процессов по запросу). Наследуются только необходимые ресурсы, используется fork для запуска нового процесса, но благодаря однопоточной реализации процесса-фабрики, это делается безопасно. Доступен только на Unix платформах с поддержкой передачи файловых дескрипторов через pipes (что может противоречить политике безопасности на многих системах).\n",
    "\n",
    "Для выбора метода используется multiprocessing.set_start_method(method)\n",
    "\n",
    "import multiprocessing\n",
    "...\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    multiprocessing.set_start_method('forkserver')\n",
    "    ...\n",
    "\n",
    "В этом примере мы выбрали forkserver механизм создания дочерних процессов.\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Общая память\n",
    "\n",
    "Чтобы создать область общей памяти, нужно указать ОС сколько памяти нужно выделить. Для вычисления объема памяти обязательно надо указать тип данных, который будет использоваться, и количество элементов для сложных типов. Кроме того, механизмы ограничения доступа к общему ресурсу также надо обеспечить самостоятельно, иначе данные можно испортить при попытке одновременного доступа для изменения из разных процессов.\n",
    "\n",
    "В этом примере мы воспользовались механизмом общей памяти Value. Тип данных был выбран десятичный ('d'). Более подробно о доступных типах и их названиях можно узнать из документации."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0\n"
     ]
    }
   ],
   "source": [
    "from multiprocessing import Process, Value, RLock, current_process\n",
    "from time import sleep\n",
    "import logging\n",
    "import sys\n",
    "\n",
    "logger = logging.getLogger()\n",
    "stream_handler = logging.StreamHandler()\n",
    "logger.addHandler(stream_handler)\n",
    "logger.setLevel(logging.DEBUG)\n",
    "\n",
    "\n",
    "def worker(val: Value):\n",
    "    logger.debug(f'Started {current_process().name}')\n",
    "    sleep(1)\n",
    "    with val.get_lock():\n",
    "        val.value += 1\n",
    "    logger.debug(f'Done {current_process().name}')\n",
    "    sys.exit(0)\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    lock = RLock()\n",
    "    value = Value('d', 0, lock=lock)\n",
    "    pr1 = Process(target=worker, args=(value, ))\n",
    "    pr1.start()\n",
    "    pr2 = Process(target=worker, args=(value, ))\n",
    "    pr2.start()\n",
    "\n",
    "    pr1.join()\n",
    "    pr2.join()\n",
    "\n",
    "    print(value.value)  # 2.0"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Давайте разберем более сложный пример, с использованием структур в общей памяти:\n",
    "\n",
    "В этом примере мы создали:\n",
    "\n",
    "    структуру Point, которая описывает координаты точки на плоскости;\n",
    "    дробное число number;\n",
    "    строковую переменную string (поддерживаются только byte-строки);\n",
    "    массив array который содержит координаты точек согласно структуре Point.\n",
    "\n",
    "Обратите внимание, для описания полей структуры надо их поместить в список кортежей _ fields_, где каждый кортеж — это имя и тип поля. Массив Array ведет себя во многом как список и позволяет хранить в нем разнотипные данные, но его размер статичен и добавлять/удалять элементы нельзя. Равно как и менять тип существующих.\n",
    "\n",
    "Также в структуры данных мы передали механизм блокировки через параметр lock. Как Value, так и Array обеспечивают блокировку ресурса, к которому можно получить доступ, чтобы читать, так и обновлять данные. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.5\n",
      "b'hello world'\n",
      "[(1.0, -6.0), (-5.0, 2.0), (2.0, 9.0)]\n"
     ]
    }
   ],
   "source": [
    "from multiprocessing import Process, RLock, current_process\n",
    "from multiprocessing.sharedctypes import Value, Array\n",
    "from ctypes import Structure, c_double\n",
    "import logging\n",
    "\n",
    "logger = logging.getLogger()\n",
    "stream_handler = logging.StreamHandler()\n",
    "logger.addHandler(stream_handler)\n",
    "logger.setLevel(logging.DEBUG)\n",
    "\n",
    "\n",
    "class Point(Structure):\n",
    "    _fields_ = [('x', c_double), ('y', c_double)]\n",
    "\n",
    "\n",
    "def modify(num: Value, string: Array, arr: Array):\n",
    "    logger.debug(f'Started {current_process().name}')\n",
    "    logger.debug(f\"Change num: {num.value}\")\n",
    "    with num.get_lock():\n",
    "        num.value **= 2\n",
    "    logger.debug(f\"to num: {num.value}\")\n",
    "    with string.get_lock():\n",
    "        string.value = string.value.upper()\n",
    "    with arr.get_lock():\n",
    "        for a in arr:\n",
    "            a.x **= 2\n",
    "            a.y **= 2\n",
    "    logger.debug(f'Done {current_process().name}')\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    lock = RLock()\n",
    "    number = Value(c_double, 1.5, lock=lock)\n",
    "    string = Array('c', b'hello world', lock=lock)\n",
    "    array = Array(Point, [(1, -6), (-5, 2), (2, 9)], lock=lock)\n",
    "\n",
    "    p = Process(target=modify, args=(number, string, array))\n",
    "    p2 = Process(target=modify, args=(number, string, array))\n",
    "    p.start()\n",
    "    p2.start()\n",
    "    p.join()\n",
    "    p2.join()\n",
    "    print(number.value)\n",
    "    print(string.value)\n",
    "    print([(arr.x, arr.y) for arr in array])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Менеджер ресурсов\n",
    "\n",
    "Более требовательный к ресурсам, но и более удобный в использовании механизм обмена данными между процессами — это менеджер ресурсов. Основное преимущество — возможность работать по сети и реализовать распределенные вычисления между несколькими компьютерами в одной сети, реализация Python-like списков и словарей.\n",
    "\n",
    "Недостатки:\n",
    "\n",
    "    Необходимость синхронизировать доступ к общим ресурсам;\n",
    "    Ограничение на поддерживаемые типы;\n",
    "    Сложный API.\n",
    "\n",
    "Рассмотрим следующий пример:\n",
    "\n",
    "В этом примере мы запустили пять процессов и в словарь m добавили, для каждого процесса его pid — идентификатор процесса. Все это было создано и управлялось менеджером Manager."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{}\n"
     ]
    }
   ],
   "source": [
    "from multiprocessing import Process, Manager, current_process\n",
    "from random import randint\n",
    "from time import sleep\n",
    "import logging\n",
    "\n",
    "logger = logging.getLogger()\n",
    "stream_handler = logging.StreamHandler()\n",
    "logger.addHandler(stream_handler)\n",
    "logger.setLevel(logging.DEBUG)\n",
    "\n",
    "\n",
    "def worker(delay, val: Manager):\n",
    "    name = current_process().name\n",
    "    logger.debug(f'Started: {name}')\n",
    "    sleep(delay)\n",
    "    val[name] = current_process().pid\n",
    "    logger.debug(f'Done: {name}')\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    with Manager() as manager:\n",
    "        m = manager.dict()\n",
    "        processes = []\n",
    "        for i in range(5):\n",
    "            pr = Process(target=worker, args=(randint(1, 3), m))\n",
    "            pr.start()\n",
    "            processes.append(pr)\n",
    "\n",
    "        [pr.join() for pr in processes]\n",
    "        print(m)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pipe (канал)\n",
    "\n",
    "ласс Pipe модуля multiprocessing возвращает парный кортеж (conn1, conn2), состоящий из объектов Connection, представляющих концы одного канала.\n",
    "\n",
    "Класс Pipe принимает аргумент дуплекс duplex, который по умолчанию равен True. Тогда канал является двунаправленным, если же duplex=False, то тогда канал является однонаправленным и тогда conn1 используется для приема сообщений, а conn2 для отправки сообщений.\n",
    "\n",
    "Объекты conn1 и conn2 имеют ряд методов, основные это:\n",
    "\n",
    "    send — отправляет объект на другой конец соединения\n",
    "    recv — возвращает объект, отправленный с другого конца соединения\n",
    "    close закрывает соединение\n",
    "\n",
    "В этом примере мы пишем в каналы из родительского процесса sender1.send(8) и sender2.send(16), а читаем из дочерних pipe.recv() внутри функции worker."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from multiprocessing import Pipe, Process, current_process\n",
    "from time import sleep\n",
    "import sys\n",
    "import logging\n",
    "\n",
    "logger = logging.getLogger()\n",
    "stream_handler = logging.StreamHandler()\n",
    "logger.addHandler(stream_handler)\n",
    "logger.setLevel(logging.DEBUG)\n",
    "\n",
    "recipient1, sender1 = Pipe()\n",
    "recipient2, sender2 = Pipe()\n",
    "\n",
    "\n",
    "def worker(pipe: Pipe):\n",
    "    name = current_process().name\n",
    "    logger.debug(f'{name} started...')\n",
    "    val = pipe.recv()\n",
    "    logger.debug(val**2)\n",
    "    sys.exit(0)\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    w1 = Process(target=worker, args=(recipient1, ))\n",
    "    w2 = Process(target=worker, args=(recipient2, ))\n",
    "\n",
    "    w1.start()\n",
    "    w2.start()\n",
    "\n",
    "    sender1.send(8)\n",
    "    sleep(1)\n",
    "    sender2.send(16)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Очереди задач\n",
    "\n",
    "Отдельный механизм обмена данными между процессами — это очереди. Очередь позволяет \"положить\" данные для обработки одним из \"работников\" и потом проконтролировать, когда \"работник\" завершил обработку. Очереди — это средство коммуникации между одним отправителем, чаще всего его называют master, и любым количеством получателей сообщений, часто их называют slave или в более нейтральном тоне — worker.\n",
    "\n",
    "Объектов в очереди может быть более одного. Очередь может быть ограниченна по размеру если нужно. Очередь гарантирует порядок сообщений и невозможность получения одного сообщения несколькими получателями.\n",
    "\n",
    "Очереди в Python реализованы в классах Queue и JoinableQueue:\n",
    "\n",
    "В этом примере мы создали два процесса w1 и w2, которые берут из очереди q себе задачи и выполняют их. Наш основной процесс, исполняющий роль master, кладет задачи в очередь q, но никак не контролирует их выполнение, а процессы worker читают сообщение из очереди и завершаются."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from multiprocessing import Queue, Process, current_process\n",
    "from time import sleep\n",
    "import sys\n",
    "import logging\n",
    "\n",
    "logger = logging.getLogger()\n",
    "stream_handler = logging.StreamHandler()\n",
    "logger.addHandler(stream_handler)\n",
    "logger.setLevel(logging.DEBUG)\n",
    "\n",
    "q = Queue()\n",
    "\n",
    "\n",
    "def worker(queue: Queue):\n",
    "    name = current_process().name\n",
    "    logger.debug(f'{name} started...')\n",
    "    val = queue.get()\n",
    "    logger.debug(f'{name} {val**2}')\n",
    "    sys.exit(0)\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    w1 = Process(target=worker, args=(q, ))\n",
    "    w2 = Process(target=worker, args=(q, ))\n",
    "\n",
    "    w1.start()\n",
    "    w2.start()\n",
    "\n",
    "    q.put(8)\n",
    "    sleep(1)\n",
    "    q.put(16)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Для контролирования процесса завершения задач можно использовать класс JoinableQueue:\n",
    "\n",
    "В этом примере master-процесс (основной процесс) ожидает выполнения задач от рабочих процессов с помощью вызовы метода jq.join() у экземпляра очереди JoinableQueue. Сами worker-процессы уведомляют master об успешном выполнении задачи, через вызов метода очереди jqueue.task_done(). Это позволяет держать в курсе master-процесс о состоянии завершения рабочего процесса и строчка кода print('Finished') выполнится только, когда все рабочие процессы будут завершены."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from multiprocessing import JoinableQueue, Process, current_process\n",
    "from time import sleep\n",
    "import sys\n",
    "import logging\n",
    "\n",
    "logger = logging.getLogger()\n",
    "stream_handler = logging.StreamHandler()\n",
    "logger.addHandler(stream_handler)\n",
    "logger.setLevel(logging.DEBUG)\n",
    "\n",
    "jq = JoinableQueue()\n",
    "\n",
    "\n",
    "def worker(jqueue: JoinableQueue):\n",
    "    name = current_process().name\n",
    "    logger.debug(f'{name} started...')\n",
    "    val = jqueue.get()\n",
    "    logger.debug(f'{name} {val**2}')\n",
    "    sleep(1)\n",
    "    jqueue.task_done()\n",
    "    sys.exit(0)\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    w1 = Process(target=worker, args=(jq, ))\n",
    "    w2 = Process(target=worker, args=(jq, ))\n",
    "\n",
    "    w1.start()\n",
    "    w2.start()\n",
    "\n",
    "    jq.put(8)\n",
    "    sleep(1)\n",
    "    jq.put(16)\n",
    "    jq.join()\n",
    "    print('Finished')\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Пул процессов\n",
    "\n",
    "Создание процессов с помощью пакета multiprocessing\n",
    "\n",
    "Для упрощения коммуникации в пакете multiprocessing есть класс, реализующий пул процессов по аналогии с concurrent.futures.\n",
    "\n",
    "Пул процессов из multiprocessing дает больше контроля, чем пул из concurrent.futures. Основные возможности:\n",
    "\n",
    "    разбивает входную последовательность на блоки и выполняет параллельную обработку поблочно, так можно уменьшить объем используемой памяти;\n",
    "    асинхронное выполнение, немного ускоряет получение результатов, если порядок не важен;\n",
    "    передача кортежа аргументов в target-функцию;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from multiprocessing import Pool, current_process\n",
    "import logging\n",
    "\n",
    "logger = logging.getLogger()\n",
    "stream_handler = logging.StreamHandler()\n",
    "logger.addHandler(stream_handler)\n",
    "logger.setLevel(logging.DEBUG)\n",
    "\n",
    "\n",
    "def worker(x):\n",
    "    logger.debug(f\"pid={current_process().pid}, x={x}\")\n",
    "    return x*x\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    with Pool(processes=2) as pool:\n",
    "        logger.debug(pool.map(worker, range(10)))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Создание процессов с помощью пакета concurrent\n",
    "\n",
    "\n",
    "Пакет concurrent.futures также реализует API Executor для пула процессов в классе ProcessPoolExecutor.\n",
    "\n",
    "Основные возможности ограничены API Executor. Удобно использовать ProcessPoolExecutor там, где необходимо выполнить CPU-bound задачу в async коде и реализовано именно для поддержки выполнения блокирующих CPU-bound задач в async приложениях (с async мы познакомимся в \"Модуль 5: Асинхронное программирование в Python\")."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "BrokenProcessPool",
     "evalue": "A process in the process pool was terminated abruptly while the future was running or pending.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mBrokenProcessPool\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 31\u001b[0m\n\u001b[0;32m     29\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39m__name__\u001b[39m \u001b[39m==\u001b[39m \u001b[39m'\u001b[39m\u001b[39m__main__\u001b[39m\u001b[39m'\u001b[39m:\n\u001b[0;32m     30\u001b[0m     \u001b[39mwith\u001b[39;00m concurrent\u001b[39m.\u001b[39mfutures\u001b[39m.\u001b[39mProcessPoolExecutor(\u001b[39m4\u001b[39m) \u001b[39mas\u001b[39;00m executor:\n\u001b[1;32m---> 31\u001b[0m         \u001b[39mfor\u001b[39;00m number, prime \u001b[39min\u001b[39;00m \u001b[39mzip\u001b[39m(PRIMES, executor\u001b[39m.\u001b[39mmap(is_prime, PRIMES)):\n\u001b[0;32m     32\u001b[0m             \u001b[39mprint\u001b[39m(\u001b[39m'\u001b[39m\u001b[39m%d\u001b[39;00m\u001b[39m is prime: \u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m'\u001b[39m \u001b[39m%\u001b[39m (number, prime))\n",
      "File \u001b[1;32mC:\\Program Files\\WindowsApps\\PythonSoftwareFoundation.Python.3.10_3.10.2544.0_x64__qbz5n2kfra8p0\\lib\\concurrent\\futures\\process.py:570\u001b[0m, in \u001b[0;36m_chain_from_iterable_of_lists\u001b[1;34m(iterable)\u001b[0m\n\u001b[0;32m    564\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_chain_from_iterable_of_lists\u001b[39m(iterable):\n\u001b[0;32m    565\u001b[0m     \u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m    566\u001b[0m \u001b[39m    Specialized implementation of itertools.chain.from_iterable.\u001b[39;00m\n\u001b[0;32m    567\u001b[0m \u001b[39m    Each item in *iterable* should be a list.  This function is\u001b[39;00m\n\u001b[0;32m    568\u001b[0m \u001b[39m    careful not to keep references to yielded objects.\u001b[39;00m\n\u001b[0;32m    569\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 570\u001b[0m     \u001b[39mfor\u001b[39;00m element \u001b[39min\u001b[39;00m iterable:\n\u001b[0;32m    571\u001b[0m         element\u001b[39m.\u001b[39mreverse()\n\u001b[0;32m    572\u001b[0m         \u001b[39mwhile\u001b[39;00m element:\n",
      "File \u001b[1;32mC:\\Program Files\\WindowsApps\\PythonSoftwareFoundation.Python.3.10_3.10.2544.0_x64__qbz5n2kfra8p0\\lib\\concurrent\\futures\\_base.py:621\u001b[0m, in \u001b[0;36mExecutor.map.<locals>.result_iterator\u001b[1;34m()\u001b[0m\n\u001b[0;32m    618\u001b[0m \u001b[39mwhile\u001b[39;00m fs:\n\u001b[0;32m    619\u001b[0m     \u001b[39m# Careful not to keep a reference to the popped future\u001b[39;00m\n\u001b[0;32m    620\u001b[0m     \u001b[39mif\u001b[39;00m timeout \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m--> 621\u001b[0m         \u001b[39myield\u001b[39;00m _result_or_cancel(fs\u001b[39m.\u001b[39;49mpop())\n\u001b[0;32m    622\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    623\u001b[0m         \u001b[39myield\u001b[39;00m _result_or_cancel(fs\u001b[39m.\u001b[39mpop(), end_time \u001b[39m-\u001b[39m time\u001b[39m.\u001b[39mmonotonic())\n",
      "File \u001b[1;32mC:\\Program Files\\WindowsApps\\PythonSoftwareFoundation.Python.3.10_3.10.2544.0_x64__qbz5n2kfra8p0\\lib\\concurrent\\futures\\_base.py:319\u001b[0m, in \u001b[0;36m_result_or_cancel\u001b[1;34m(***failed resolving arguments***)\u001b[0m\n\u001b[0;32m    317\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m    318\u001b[0m     \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m--> 319\u001b[0m         \u001b[39mreturn\u001b[39;00m fut\u001b[39m.\u001b[39;49mresult(timeout)\n\u001b[0;32m    320\u001b[0m     \u001b[39mfinally\u001b[39;00m:\n\u001b[0;32m    321\u001b[0m         fut\u001b[39m.\u001b[39mcancel()\n",
      "File \u001b[1;32mC:\\Program Files\\WindowsApps\\PythonSoftwareFoundation.Python.3.10_3.10.2544.0_x64__qbz5n2kfra8p0\\lib\\concurrent\\futures\\_base.py:458\u001b[0m, in \u001b[0;36mFuture.result\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m    456\u001b[0m     \u001b[39mraise\u001b[39;00m CancelledError()\n\u001b[0;32m    457\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_state \u001b[39m==\u001b[39m FINISHED:\n\u001b[1;32m--> 458\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m__get_result()\n\u001b[0;32m    459\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    460\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mTimeoutError\u001b[39;00m()\n",
      "File \u001b[1;32mC:\\Program Files\\WindowsApps\\PythonSoftwareFoundation.Python.3.10_3.10.2544.0_x64__qbz5n2kfra8p0\\lib\\concurrent\\futures\\_base.py:403\u001b[0m, in \u001b[0;36mFuture.__get_result\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    401\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_exception:\n\u001b[0;32m    402\u001b[0m     \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m--> 403\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_exception\n\u001b[0;32m    404\u001b[0m     \u001b[39mfinally\u001b[39;00m:\n\u001b[0;32m    405\u001b[0m         \u001b[39m# Break a reference cycle with the exception in self._exception\u001b[39;00m\n\u001b[0;32m    406\u001b[0m         \u001b[39mself\u001b[39m \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n",
      "\u001b[1;31mBrokenProcessPool\u001b[0m: A process in the process pool was terminated abruptly while the future was running or pending."
     ]
    }
   ],
   "source": [
    "import concurrent.futures\n",
    "import math\n",
    "\n",
    "\n",
    "PRIMES = [\n",
    "    112272535095293,\n",
    "    112582705942171,\n",
    "    112272535095293,\n",
    "    115280095190773,\n",
    "    115797848077099,\n",
    "    1099726899285419]\n",
    "\n",
    "\n",
    "def is_prime(n):\n",
    "    if n < 2:\n",
    "        return False\n",
    "    if n == 2:\n",
    "        return True\n",
    "    if n % 2 == 0:\n",
    "        return False\n",
    "\n",
    "    sqrt_n = int(math.floor(math.sqrt(n)))\n",
    "    for i in range(3, sqrt_n + 1, 2):\n",
    "        if n % i == 0:\n",
    "            return False\n",
    "    return True\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    with concurrent.futures.ProcessPoolExecutor(4) as executor:\n",
    "        for number, prime in zip(PRIMES, executor.map(is_prime, PRIMES)):\n",
    "            print('%d is prime: %s' % (number, prime))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before func_1 sleep_time=2\n",
      "After func_1 sleep_time=2\n",
      "Before func_2 sleep_time=2\n",
      "After func_2 sleep_time=2\n",
      "4.023967742919922\n"
     ]
    }
   ],
   "source": [
    "from multiprocessing import Process\n",
    "from time import sleep, time\n",
    "\n",
    "before = time()\n",
    "\n",
    "def func_1(sleep_time: int):\n",
    "    print(f'Before func_1 {sleep_time=}')\n",
    "    sleep(sleep_time)\n",
    "    print(f'After func_1 {sleep_time=}')\n",
    "\n",
    "def func_2(sleep_time: int):\n",
    "    print(f'Before func_2 {sleep_time=}')\n",
    "    sleep(sleep_time)\n",
    "    print(f'After func_2 {sleep_time=}')\n",
    "\n",
    "func_1(2)\n",
    "func_2(2)\n",
    "\n",
    "after = time()\n",
    "\n",
    "t1 = Process(target=func_1, args=(3,))\n",
    "t2 = Process(target=func_2, args=(5,))\n",
    "\n",
    "t1.start()\n",
    "t2.start()\n",
    "\n",
    "t1.join()\n",
    "t2.join()\n",
    "\n",
    "print(f'{after-before}')\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ТИПИ ЗАПУСКУ МУЛЬТИПРОЦЕСІВ\n",
    "spawn (win, mac)   fork (linux, mac)  forkserver (linux, mac) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before func_1 sleep_time=2\n",
      "After func_1 sleep_time=2\n",
      "Before func_2 sleep_time=2\n",
      "After func_2 sleep_time=2\n",
      "4.015461206436157\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "context has already been set",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[2], line 27\u001b[0m\n\u001b[0;32m     24\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\u001b[39m{\u001b[39;00mafter\u001b[39m-\u001b[39mbefore\u001b[39m}\u001b[39;00m\u001b[39m'\u001b[39m)\n\u001b[0;32m     26\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39m__name__\u001b[39m \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39m__main__\u001b[39m\u001b[39m\"\u001b[39m:\n\u001b[1;32m---> 27\u001b[0m     multiprocessing\u001b[39m.\u001b[39;49mset_start_method(\u001b[39m'\u001b[39;49m\u001b[39mspawn\u001b[39;49m\u001b[39m'\u001b[39;49m) \u001b[39m#выбираем метод запуска\u001b[39;00m\n\u001b[0;32m     28\u001b[0m     t1 \u001b[39m=\u001b[39m Process(target\u001b[39m=\u001b[39mfunc_1, args\u001b[39m=\u001b[39m(\u001b[39m3\u001b[39m,))\n\u001b[0;32m     29\u001b[0m     t2 \u001b[39m=\u001b[39m Process(target\u001b[39m=\u001b[39mfunc_2, args\u001b[39m=\u001b[39m(\u001b[39m5\u001b[39m,))\n",
      "File \u001b[1;32mC:\\Program Files\\WindowsApps\\PythonSoftwareFoundation.Python.3.10_3.10.2544.0_x64__qbz5n2kfra8p0\\lib\\multiprocessing\\context.py:247\u001b[0m, in \u001b[0;36mDefaultContext.set_start_method\u001b[1;34m(self, method, force)\u001b[0m\n\u001b[0;32m    245\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mset_start_method\u001b[39m(\u001b[39mself\u001b[39m, method, force\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m):\n\u001b[0;32m    246\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_actual_context \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mand\u001b[39;00m \u001b[39mnot\u001b[39;00m force:\n\u001b[1;32m--> 247\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mRuntimeError\u001b[39;00m(\u001b[39m'\u001b[39m\u001b[39mcontext has already been set\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[0;32m    248\u001b[0m     \u001b[39mif\u001b[39;00m method \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mand\u001b[39;00m force:\n\u001b[0;32m    249\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_actual_context \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n",
      "\u001b[1;31mRuntimeError\u001b[0m: context has already been set"
     ]
    }
   ],
   "source": [
    "from multiprocessing import Process\n",
    "import multiprocessing\n",
    "from time import sleep, time\n",
    "\n",
    "before = time()\n",
    "\n",
    "def func_1(sleep_time: int):\n",
    "    print(f'Before func_1 {sleep_time=}')\n",
    "    sleep(sleep_time)\n",
    "    print(f'After func_1 {sleep_time=}')\n",
    "\n",
    "def func_2(sleep_time: int):\n",
    "    print(f'Before func_2 {sleep_time=}')\n",
    "    sleep(sleep_time)\n",
    "    print(f'After func_2 {sleep_time=}')\n",
    "\n",
    "func_1(2)\n",
    "func_2(2)\n",
    "\n",
    "after = time()\n",
    "\n",
    "\n",
    "\n",
    "print(f'{after-before}')\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    multiprocessing.set_start_method('spawn') #выбираем метод запуска\n",
    "    t1 = Process(target=func_1, args=(3,))\n",
    "    t2 = Process(target=func_2, args=(5,))\n",
    "\n",
    "    t1.start()\n",
    "    t2.start()\n",
    "\n",
    "    t1.join()\n",
    "    t2.join()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Скачування picsum.photos у багатоканальному та багатопроцесорному варіанті"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests #пакет що робить запити\n",
    "\n",
    "url = 'https://picsum.photos/200/300'\n",
    "\n",
    "path = 'F:\\GoIT_Python_Project\\Images'\n",
    "\n",
    "def download(url):\n",
    "    response = requests.get(url)\n",
    "    with open(path, 'wb') as file:\n",
    "        file.write(response.content)\n",
    "    \n",
    "\n",
    "download(url=url)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests #пакет що робить запити\n",
    "\n",
    "url = 'https://picsum.photos/200/300'\n",
    "\n",
    "path = 'F:\\GoIT_Python_Project\\Images\\image_{n}.jpg'\n",
    "\n",
    "def download(n: int):\n",
    "    response = requests.get(url)\n",
    "    file_path = path.format(n=n)\n",
    "    # file_path = 'F:\\GoIT_Python_Project\\Images\\image_{n}.jpg'.format(n=n)\n",
    "    with open(file_path, 'wb') as file:\n",
    "        file.write(response.content)\n",
    "    \n",
    "for n in range(10):\n",
    "        download(n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MainThread Starting new HTTPS connection (1): picsum.photos:443\n",
      "MainThread https://picsum.photos:443 \"GET /200/300 HTTP/1.1\" 302 0\n",
      "MainThread Starting new HTTPS connection (1): i.picsum.photos:443\n",
      "MainThread https://i.picsum.photos:443 \"GET /id/560/200/300.jpg?hmac=Qw6Gj4Q7nEunQocIfP9eSZ12CmRwQjYRMHvKIsnf08Y HTTP/1.1\" 200 16131\n",
      "MainThread Returned data: data=None. Run time: 0.7497816000031889\n",
      "MainThread Starting new HTTPS connection (1): picsum.photos:443\n",
      "MainThread https://picsum.photos:443 \"GET /200/300 HTTP/1.1\" 302 0\n",
      "MainThread Starting new HTTPS connection (1): i.picsum.photos:443\n",
      "MainThread https://i.picsum.photos:443 \"GET /id/795/200/300.jpg?hmac=nVCcTtoBktz0APjPmi8v8r7YJ_Tw7u9vVX6gE1WTIxw HTTP/1.1\" 200 11812\n",
      "MainThread Returned data: data=None. Run time: 0.6908146999994642\n",
      "MainThread Starting new HTTPS connection (1): picsum.photos:443\n",
      "MainThread https://picsum.photos:443 \"GET /200/300 HTTP/1.1\" 302 0\n",
      "MainThread Starting new HTTPS connection (1): i.picsum.photos:443\n",
      "MainThread https://i.picsum.photos:443 \"GET /id/955/200/300.jpg?hmac=I4JBGrEHxErLo6XCZM73YcpyhJjX3GxLPggnlxcdU24 HTTP/1.1\" 200 24395\n",
      "MainThread Returned data: data=None. Run time: 0.8836522000055993\n",
      "MainThread Starting new HTTPS connection (1): picsum.photos:443\n",
      "MainThread https://picsum.photos:443 \"GET /200/300 HTTP/1.1\" 302 0\n",
      "MainThread Starting new HTTPS connection (1): i.picsum.photos:443\n",
      "MainThread https://i.picsum.photos:443 \"GET /id/109/200/300.jpg?hmac=wtAwGwuVC3CUO3okhkSJZKm-wZY_evzXIo1F46OtKKo HTTP/1.1\" 200 7534\n",
      "MainThread Returned data: data=None. Run time: 1.0173167000029935\n",
      "MainThread Starting new HTTPS connection (1): picsum.photos:443\n",
      "MainThread https://picsum.photos:443 \"GET /200/300 HTTP/1.1\" 302 0\n",
      "MainThread Starting new HTTPS connection (1): i.picsum.photos:443\n",
      "MainThread https://i.picsum.photos:443 \"GET /id/679/200/300.jpg?hmac=TZThBzAXAPG_yB5mI6BN5MmYjEPA76LJR73t99aDOZU HTTP/1.1\" 200 5444\n",
      "MainThread Returned data: data=None. Run time: 0.7460740000024089\n",
      "MainThread Starting new HTTPS connection (1): picsum.photos:443\n",
      "MainThread https://picsum.photos:443 \"GET /200/300 HTTP/1.1\" 302 0\n",
      "MainThread Starting new HTTPS connection (1): i.picsum.photos:443\n",
      "MainThread https://i.picsum.photos:443 \"GET /id/576/200/300.jpg?hmac=Uf-okGnisfAphCT3N-WTyzaG-e-r9yvOhY3W43DMWwA HTTP/1.1\" 200 14644\n",
      "MainThread Returned data: data=None. Run time: 0.7399736000006669\n",
      "MainThread Starting new HTTPS connection (1): picsum.photos:443\n",
      "MainThread https://picsum.photos:443 \"GET /200/300 HTTP/1.1\" 302 0\n",
      "MainThread Starting new HTTPS connection (1): i.picsum.photos:443\n",
      "MainThread https://i.picsum.photos:443 \"GET /id/277/200/300.jpg?hmac=8wIsJ0ZOFtBSrTpSE0M37XZG2dXMzDTL2_dgppOaP0Y HTTP/1.1\" 200 8010\n",
      "MainThread Returned data: data=None. Run time: 0.7452231999996002\n",
      "MainThread Starting new HTTPS connection (1): picsum.photos:443\n",
      "MainThread https://picsum.photos:443 \"GET /200/300 HTTP/1.1\" 302 0\n",
      "MainThread Starting new HTTPS connection (1): i.picsum.photos:443\n",
      "MainThread https://i.picsum.photos:443 \"GET /id/419/200/300.jpg?hmac=jvSs1zyCZ3ATdTlvdfcTKBBGcrgnCk3EAvZt352Fbco HTTP/1.1\" 200 14480\n",
      "MainThread Returned data: data=None. Run time: 0.7100362999990466\n",
      "MainThread Starting new HTTPS connection (1): picsum.photos:443\n",
      "MainThread https://picsum.photos:443 \"GET /200/300 HTTP/1.1\" 302 0\n",
      "MainThread Starting new HTTPS connection (1): i.picsum.photos:443\n",
      "MainThread https://i.picsum.photos:443 \"GET /id/930/200/300.jpg?hmac=mVMk8tDbj7-Utfz1VfwDV9UYCVrv9H0ktf0m1C0iBek HTTP/1.1\" 200 7740\n",
      "MainThread Returned data: data=None. Run time: 0.760181300000113\n",
      "MainThread Starting new HTTPS connection (1): picsum.photos:443\n",
      "MainThread https://picsum.photos:443 \"GET /200/300 HTTP/1.1\" 302 0\n",
      "MainThread Starting new HTTPS connection (1): i.picsum.photos:443\n",
      "MainThread https://i.picsum.photos:443 \"GET /id/698/200/300.jpg?hmac=2Z_fr-yUH1ByQu36MAR319aTCndT4FjG1VBksAKGVKU HTTP/1.1\" 200 14484\n",
      "MainThread Returned data: data=None. Run time: 0.7602075000031618\n",
      "MainThread Returned data: data=None. Run time: 7.8193260000043665\n"
     ]
    }
   ],
   "source": [
    "import requests #пакет що робить запити\n",
    "from timeit import default_timer\n",
    "import logging\n",
    "\n",
    "logging.basicConfig(level=logging.DEBUG, format='%(threadName)s %(message)s')\n",
    "\n",
    "url = 'https://picsum.photos/200/300'\n",
    "\n",
    "path = 'F:\\GoIT_Python_Project\\Images\\image_{n}.jpg'\n",
    "\n",
    "def execute_time(func): #Делаем фенкцию декоратор\n",
    "    def delta_time(*args, **kwargs):\n",
    "        t1 = default_timer()\n",
    "        data = func(*args, **kwargs)\n",
    "        delta = default_timer() - t1\n",
    "        logging.info(f'Returned data: {data=}. Run time: {delta}')\n",
    "    \n",
    "    return delta_time\n",
    "\n",
    "@execute_time\n",
    "def download(n: int):\n",
    "    response = requests.get(url)\n",
    "    file_path = path.format(n=n)\n",
    "    # file_path = 'F:\\GoIT_Python_Project\\Images\\image_{n}.jpg'.format(n=n)\n",
    "    with open(file_path, 'wb') as file:\n",
    "        file.write(response.content)\n",
    "\n",
    "@execute_time\n",
    "def download_all(count: int):\n",
    "    for n in range(10):\n",
    "            download(count)\n",
    "\n",
    "download_all(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests #пакет що робить запити\n",
    "from timeit import default_timer\n",
    "import logging\n",
    "\n",
    "logging.basicConfig(level=logging.DEBUG, format='%(threadName)s %(message)s')\n",
    "\n",
    "url = 'https://picsum.photos/200/300'\n",
    "\n",
    "path = 'F:\\GoIT_Python_Project\\Images\\image_{n}.jpg'\n",
    "\n",
    "def execute_time(func): #Делаем фенкцию декоратор\n",
    "    def delta_time(*args, **kwargs):\n",
    "        t1 = default_timer()\n",
    "        data = func(*args, **kwargs)\n",
    "        delta = default_timer() - t1\n",
    "        logging.info(f'Returned data: {data=}. Run time: {delta}')\n",
    "    \n",
    "    return delta_time\n",
    "\n",
    "@execute_time\n",
    "def download(n: int):\n",
    "    response = requests.get(url)\n",
    "    file_path = path.format(n=n)\n",
    "    # file_path = 'F:\\GoIT_Python_Project\\Images\\image_{n}.jpg'.format(n=n)\n",
    "    with open(file_path, 'wb') as file:\n",
    "        file.write(response.content)\n",
    "\n",
    "@execute_time\n",
    "def download_all(count: int):\n",
    "    for n in range(10):\n",
    "            download(count)\n",
    "\n",
    "download_all(15)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ThreadPoolExecutor-1_1 Starting new HTTPS connection (1): picsum.photos:443\n",
      "ThreadPoolExecutor-1_0 Starting new HTTPS connection (1): picsum.photos:443\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cpu_count()=4\n",
      "max_workers=9\n",
      "result=<generator object Executor.map.<locals>.result_iterator at 0x0000018310868B30>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ThreadPoolExecutor-1_1 https://picsum.photos:443 \"GET /200/300 HTTP/1.1\" 302 0\n",
      "ThreadPoolExecutor-1_1 Starting new HTTPS connection (1): i.picsum.photos:443\n",
      "ThreadPoolExecutor-1_0 https://picsum.photos:443 \"GET /200/300 HTTP/1.1\" 302 0\n",
      "ThreadPoolExecutor-1_0 Starting new HTTPS connection (1): i.picsum.photos:443\n",
      "ThreadPoolExecutor-1_0 https://i.picsum.photos:443 \"GET /id/82/200/300.jpg?hmac=hfuNcoCWsYuVOmlcRdKAieM4Ax03DjM-mpVlqRUdGfc HTTP/1.1\" 200 12405\n",
      "ThreadPoolExecutor-1_0 Returned data: data=None. Run time: 0.6873428999970201\n",
      "ThreadPoolExecutor-1_0 Starting new HTTPS connection (1): picsum.photos:443\n",
      "ThreadPoolExecutor-1_1 https://i.picsum.photos:443 \"GET /id/805/200/300.jpg?hmac=fF1qvNutYd9afa-FIuDfrsh7edNFRq6IXWnMbSuzSOs HTTP/1.1\" 200 5525\n",
      "ThreadPoolExecutor-1_1 Returned data: data=None. Run time: 0.7007771000062348\n",
      "ThreadPoolExecutor-1_1 Starting new HTTPS connection (1): picsum.photos:443\n",
      "ThreadPoolExecutor-1_1 https://picsum.photos:443 \"GET /200/300 HTTP/1.1\" 302 0\n",
      "ThreadPoolExecutor-1_1 Starting new HTTPS connection (1): i.picsum.photos:443\n",
      "ThreadPoolExecutor-1_0 https://picsum.photos:443 \"GET /200/300 HTTP/1.1\" 302 0\n",
      "ThreadPoolExecutor-1_0 Starting new HTTPS connection (1): i.picsum.photos:443\n",
      "ThreadPoolExecutor-1_0 https://i.picsum.photos:443 \"GET /id/89/200/300.jpg?hmac=Mkt49bCquTyq1IBgwbLmaT43TeyQgXNig052fowQB1M HTTP/1.1\" 200 9914\n",
      "ThreadPoolExecutor-1_0 Returned data: data=None. Run time: 0.8479749999969499\n",
      "ThreadPoolExecutor-1_0 Starting new HTTPS connection (1): picsum.photos:443\n",
      "ThreadPoolExecutor-1_1 https://i.picsum.photos:443 \"GET /id/413/200/300.jpg?hmac=bfSGClFpOROonzp5IIDI-aVAQMyyCC9lSOp184Tqu4M HTTP/1.1\" 200 12515\n",
      "ThreadPoolExecutor-1_1 Returned data: data=None. Run time: 0.8948959999979706\n",
      "ThreadPoolExecutor-1_0 https://picsum.photos:443 \"GET /200/300 HTTP/1.1\" 302 0\n",
      "ThreadPoolExecutor-1_0 Starting new HTTPS connection (1): i.picsum.photos:443\n",
      "ThreadPoolExecutor-1_0 https://i.picsum.photos:443 \"GET /id/1033/200/300.jpg?hmac=856_WOyaGXSjI4FWe3_NCHU7frPtAEJaHnAJja5TMNk HTTP/1.1\" 200 11957\n",
      "ThreadPoolExecutor-1_0 Returned data: data=None. Run time: 0.8169247000041651\n",
      "MainThread Returned data: data=None. Run time: 2.3588120999920648\n"
     ]
    }
   ],
   "source": [
    "import requests #пакет що робить запити\n",
    "from timeit import default_timer\n",
    "import logging\n",
    "from threading import Thread\n",
    "from concurrent.futures import ThreadPoolExecutor\n",
    "from multiprocessing import cpu_count\n",
    "\n",
    "logging.basicConfig(level=logging.DEBUG, format='%(threadName)s %(message)s')\n",
    "\n",
    "url = 'https://picsum.photos/200/300'\n",
    "\n",
    "path = 'F:\\GoIT_Python_Project\\Images\\image_{n}.jpg'\n",
    "\n",
    "def execute_time(func): #Делаем фенкцию декоратор\n",
    "    def delta_time(*args, **kwargs):\n",
    "        t1 = default_timer()\n",
    "        data = func(*args, **kwargs)\n",
    "        delta = default_timer() - t1\n",
    "        logging.info(f'Returned data: {data=}. Run time: {delta}')\n",
    "    \n",
    "    return delta_time\n",
    "\n",
    "@execute_time\n",
    "def download(n: int):\n",
    "    response = requests.get(url)\n",
    "    file_path = path.format(n=n)\n",
    "    # file_path = 'F:\\GoIT_Python_Project\\Images\\image_{n}.jpg'.format(n=n)\n",
    "    with open(file_path, 'wb') as file:\n",
    "        file.write(response.content)\n",
    "\n",
    "\n",
    "\n",
    "@execute_time\n",
    "def download_all(count: int):\n",
    "    with ThreadPoolExecutor(max_workers=2) as executor:\n",
    "        result = executor.map(download, range(count))\n",
    "        print(f'{result=}')\n",
    "\n",
    "# Максимальное количество процессов\n",
    "max_workers = cpu_count() * 2 + 1\n",
    "print(f'{cpu_count()=}')\n",
    "print(f'{max_workers=}')\n",
    "\n",
    "download_all(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests #пакет що робить запити\n",
    "from timeit import default_timer\n",
    "import logging\n",
    "from multiprocessing import Pool\n",
    "from multiprocessing import cpu_count\n",
    "\n",
    "logging.basicConfig(level=logging.DEBUG, format='%(threadName)s %(message)s')\n",
    "\n",
    "url = 'https://picsum.photos/200/300'\n",
    "\n",
    "path = 'F:\\GoIT_Python_Project\\Images\\image_{n}.jpg'\n",
    "\n",
    "def execute_time(func): #Делаем фенкцию декоратор\n",
    "    def delta_time(*args, **kwargs):\n",
    "        t1 = default_timer()\n",
    "        data = func(*args, **kwargs)\n",
    "        delta = default_timer() - t1\n",
    "        logging.info(f'Returned data: {data=}. Run time: {delta}')\n",
    "    \n",
    "    return delta_time\n",
    "\n",
    "@execute_time\n",
    "def download(n: int):\n",
    "    response = requests.get(url)\n",
    "    file_path = path.format(n=n)\n",
    "    # file_path = 'F:\\GoIT_Python_Project\\Images\\image_{n}.jpg'.format(n=n)\n",
    "    with open(file_path, 'wb') as file:\n",
    "        file.write(response.content)\n",
    "\n",
    "\n",
    "\n",
    "@execute_time\n",
    "def download_all(count: int):\n",
    "    pool = Pool(4)\n",
    "    pool.map(download, range(count))\n",
    "\n",
    "\n",
    "download_all(15)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9 (tags/v3.10.9:1dd9be6, Dec  6 2022, 20:01:21) [MSC v.1934 64 bit (AMD64)]"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "ed7be02089ffed073fc94961a2816327ba503e6ccd40fc2b18e98827abff8348"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
